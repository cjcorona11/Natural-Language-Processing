---
title: "fakenews"
author: "Mark Braun, Chris Corona"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r Load Data, echo=F, message=F, warning=F}
library(tidyverse)
news <- read_csv("fake_or_real_news.csv")

summary(factor(news$label))
```

```{r Preprocessing, echo=F, message=F, warning=F}
library(tm)
# create corpus of text
corpus <- VCorpus(VectorSource(news$text))
# convert to all lowercase
corpus = tm_map(corpus, content_transformer(tolower))
# remove punctuation
corpus = tm_map(corpus, content_transformer(removePunctuation))
# remove stopwords
corpus = tm_map(corpus, removeWords, c(stopwords("english")))
# stemming
library(SnowballC)
corpus = tm_map(corpus, stemDocument)
# remove stopwords one more time (stemming created some stopwords again - why?)
corpus = tm_map(corpus, removeWords, c(stopwords("english"), "via", "hes", "doesnt", "didnt", "isnt"))
# create document term matrix
frequencies = DocumentTermMatrix(corpus)
# remove terms with frequencies < 0.05
sparse = removeSparseTerms(frequencies, 0.95)
# create data frame of sparse frequencies (including labels)
tSparse = as.data.frame(as.matrix(sparse))
colnames(tSparse) = make.names(colnames(tSparse), unique=T)
tSparse$label <- as.factor(news$label)
```

```{r Fakest/Realest Words, echo=F, message=F, warning=F}
library(tidyverse)
# fakest/realest words
# sum the number of times each word appears in each article label
agg <- aggregate(select(tSparse,-c(label)), by=as.data.frame(tSparse$label), FUN=sum)
# (add one so we don't divide by zero in the next step)
agg[,-1] <- agg[,-1] + 1
# get the ratios: divide by the number of fake / real articles respectively
agg[1,-1] <- agg[1,-1]/3164
agg[2,-1] <- agg[2,-1]/3171
fakeness_ratio <- agg[1,-1]/agg[2,-1]
realness_ratio <- agg[2,-1]/agg[1,-1]
# calculate fakest/realest words
fakest <- sort(fakeness_ratio, decreasing=T)[1:30]
realest <- sort(realness_ratio, decreasing=T)[1:30]
# plot fakest/realest words
par(mfrow=c(2,1))
barplot(as.numeric(fakest), names.arg=colnames(fakest), las=2, main="Fakest Words")
barplot(as.numeric(realest), names.arg=colnames(realest), las=2, main="Realest Words")
```

```{r Null Accuracy, echo=F, message=F, warning=F}
prop.table(table(tSparse$label))
```

```{r Train/Test Split, echo=F, message=F, warning=F}
# variables to split data into train and test sets
n <- dim(tSparse)[1]
k <- 10
n_k <- floor(n/k)
indices <- 1:n
split <- sample(indices, n, replace=F)

# function for calculating accuracy, precision, recall, and F1 score
score <- function(prediction, actual) {
  accuracy <- mean(prediction == actual)
  cat("Accuracy: ", accuracy, "\n")
  precision <- sum(prediction == "FAKE" & prediction == actual)/sum(prediction == "FAKE")
  cat("Precision: ", precision, "\n")
  recall <- sum(prediction == "FAKE" & prediction == actual)/sum(actual == "FAKE")
  cat("Recall: ", recall, "\n")
  f1 <- 2*precision*recall/(precision+recall)
  cat("F1: ", f1, "\n")
  out <- rep(0,4)
  out[1:4] = c(accuracy, precision, recall, f1)
  return(out)
}
```

```{r Naive Bayes, echo=F, message=F, warning=F}
library(e1071)

# initialize scores matrix
scores <- matrix(,nrow=k,ncol=4)

for(i in 1:(k-1)) {
  # train/test split
  train <- tSparse[-split[(((i-1)*n_k)+1):(i*n_k)],]
  test <- tSparse[split[(((i-1)*n_k)+1):(i*n_k)],]
  # train RF model
  modelNB = naiveBayes(label ~ ., data=train)
  # predict with RF
  predictNB = predict(modelNB, newdata=test)
  # confusion matrix
  cat("\n#######################\n")
  table(test$label, predictNB)
  cat("\n")
  scores[i,] <- score(predictNB, test$label)
}
# need one more iteration outside for-loop to account for remaining
# observations (6335-9*633) because n/k is not an integer
i <- k
# train/test split
train <- tSparse[-split[(((i-1)*n_k)+1):dim(tSparse)[1]],]
test <- tSparse[split[(((i-1)*n_k)+1):dim(tSparse)[1]],]
# train RF model
modelNB = naiveBayes(label ~ ., data=train)
# predict with RF
predictNB = predict(modelNB, newdata=test)
# confusion matrix
cat("\n#######################\n")
table(test$label, predictNB)
cat("\n")
scores[i,] <- score(predictNB, test$label)

# k-fold average scores
avg_score <- rep(NA, 4)
for(i in 1:4) {
  avg_score[i] <- mean(scores[,i])
}
avg_acc <- 0.7935259
avg_prec <- 0.7399228
avg_rec <- 0.9050575
avg_f1 <- 0.8139437
```

```{r Random Forest, echo=F, message=F, warning=F}
library(randomForest)
# initialize scores matrix
scores <- matrix(,nrow=k,ncol=4)

# warning: this takes 6-8hrs
# I summarized the scores below
for(i in 1:(k-1)) {
  # train/test split
  train <- tSparse[-split[(((i-1)*n_k)+1):(i*n_k)],]
  test <- tSparse[split[(((i-1)*n_k)+1):(i*n_k)],]
  # train RF model
  modelRF = randomForest(label ~ ., data=train)
  # predict with RF
  predictRF = predict(modelRF, newdata=test)
  # confusion matrix
  cat("\n#######################\n")
  table(test$label, predictRF)
  cat("\n")
  scores[i,] <- score(predictRF, test$label)
}
# need one more iteration outside for-loop to account for remaining
# observations (6335-9*633) because n/k is not an integer
i <- k
# train/test split
train <- tSparse[-split[(((i-1)*n_k)+1):dim(tSparse)[1]],]
test <- tSparse[split[(((i-1)*n_k)+1):dim(tSparse)[1]],]
# train RF model
modelRF = randomForest(label ~ ., data=train)
# predict with RF
predictRF = predict(modelRF, newdata=test)
# confusion matrix
cat("\n#######################\n")
table(test$label, predictRF)
cat("\n")
scores[i,] <- score(predictRF, test$label)
# k-fold average scores
avg_acc <- 0.9243769
avg_prec <- 0.9226073
avg_rec <- 0.9260733
avg_f1 <- 0.9241894
```



```{r Build N-Grams, echo=F, message=F, warning=F}
# this block of code isn't full working yet...
# I'm not exactly sure what the n-gram document term matrix even looks like
# here is a link to an article I was following
# https://medium.com/@ibtissam.makdoun/creating-n-grams-using-r-2dcc0cde4af5
library(RWeka)
BigramTokenizer <- function(x) {
  NGramTokenizer(x, Weka_control(min = 1, max = 2))
}
TrigramTokenizer <- function(x) {
  NGramTokenizer(x, Weka_control(min = 1, max = 3))
}
# create document term matrix of bigrams
frequencies2 = DocumentTermMatrix(corpus, control = list(tokenize = BigramTokenizer))
# remove terms with frequencies < 0.05
sparse2 = removeSparseTerms(frequencies2, 0.95)
# create data frame of sparse frequencies (including labels)
tSparse2 = as.data.frame(as.matrix(sparse2))
colnames(tSparse2) = make.names(colnames(tSparse2), unique=T)
tSparse2$label = news$label
tSparse2$label <- as.factor(tSparse2$label)

# create document term matrix of trigrams
frequencies3 = DocumentTermMatrix(corpus, control = list(tokenize = TrigramTokenizer))
# remove terms with frequencies < 0.05
sparse3 = removeSparseTerms(frequencies3, 0.95)
# create data frame of sparse frequencies (including labels)
tSparse3 = as.data.frame(as.matrix(sparse3))
colnames(tSparse3) = make.names(colnames(tSparse3), unique=T)
tSparse3$label = news$label
tSparse3$label <- as.factor(tSparse3$label)

for(i in 1:(k-1)) {
  # train/test split
  train2 <- tSparse2[-split[(((i-1)*n_k)+1):(i*n_k)],]
  test2 <- tSparse2[split[(((i-1)*n_k)+1):(i*n_k)],]
  train3 <- tSparse3[-split[(((i-1)*n_k)+1):(i*n_k)],]
  test3 <- tSparse3[split[(((i-1)*n_k)+1):(i*n_k)],]
  # train NB model
  modelNB2 = naiveBayes(label ~ ., data=train2)
  modelNB3 = naiveBayes(label ~ ., data=train3)
  # predict with NB
  predictNB2 = predict(modelNB2, newdata=test2)
  predictNB3 = predict(modelNB3, newdata=test3)
  # confusion matrix
  cat("\n#######################\n")
  cat("2-gram\n")
  table(test2$label, predictNB2)
  cat("\n")
  scores2[i,] <- score(predictNB2, test2$label)
  cat("\n#######################\n")
  cat("3-gram\n")
  table(test3$label, predictNB3)
  cat("\n")
  scores3[i,] <- score(predictNB3, test3$label)
}
# need one more iteration outside for-loop to account for remaining
# observations (6335-9*633) because n/k is not an integer
i <- k
# train/test split
train2 <- tSparse2[-split[(((i-1)*n_k)+1):dim(tSparse2)[1]],]
test2 <- tSparse2[split[(((i-1)*n_k)+1):dim(tSparse2)[1]],]
train3 <- tSparse3[-split[(((i-1)*n_k)+1):dim(tSparse3)[1]],]
test3 <- tSparse3[split[(((i-1)*n_k)+1):dim(tSparse3)[1]],]
# train NB model
modelNB2 = naiveBayes(label ~ ., data=train2)
modelNB3 = naiveBayes(label ~ ., data=train3)
# predict with NB
predictNB2 = predict(modelNB2, newdata=test2)
predictNB3 = predict(modelNB3, newdata=test3)
# confusion matrix
cat("\n#######################\n")
cat("2-gram\n")
table(test2$label, predictNB2)
cat("\n")
scores2[i,] <- score(predictNB2, test2$label)
cat("\n#######################\n")
cat("3-gram\n")
table(test3$label, predictNB3)
cat("\n")
scores3[i,] <- score(predictNB3, test3$label)

# k-fold average scores
avg_score2 <- rep(NA, 4)
avg_score3 <- rep(NA, 4)
for(i in 1:4) {
  avg_score2[i] <- mean(scores2[,i])
  avg_score3[i] <- mean(scores3[,i])
}
avg_acc2 <- 0.8274589
avg_prec2 <- 0.7635951
avg_rec2 <- 0.9477520
avg_f12 <- 0.8456242
avg_acc3 <- 0.8201932
avg_prec3 <- 0.7524047
avg_rec3 <- 0.9537779
avg_f13 <- 0.8410367
```


```{r Logistic Regression, echo=F, message=F, warning=F}
n <- dim(tSparse)[1]
k <- 10
n_k <- floor(n/k)
indices <- 1:n
split <- sample(indices, n, replace=F)

score <- function(prediction, actual) {
  accuracy <- mean(prediction == actual)
  cat("Accuracy: ", accuracy, "\n")
  precision <- sum(prediction == "FAKE" & prediction == actual)/sum(prediction == "FAKE")
  cat("Precision: ", precision, "\n")
  recall <- sum(prediction == "FAKE" & prediction == actual)/sum(actual == "FAKE")
  cat("Recall: ", recall, "\n")
  f1 <- 2*precision*recall/(precision+recall)
  cat("F1: ", f1, "\n")
  out <- rep(0,4)
  out[1:4] = c(accuracy, precision, recall, f1)
  return(out)
}

# initialize scores matrix
scores <- matrix(,nrow=k,ncol=4)

# warning: this takes 6-8hrs
# I summarized the scores below
for(i in 1:(k-1)) {
  # train/test split
  train <- tSparse[-split[(((i-1)*n_k)+1):(i*n_k)],]
  test <- tSparse[split[(((i-1)*n_k)+1):(i*n_k)],]
  # train LR model
  modelLR = glm(label ~ ., data=train, family="binomial")
  # predict with LR
  predictLR = predict(modelLR, newdata=test, type="response")
  predictLR = factor(round(predictLR, digits=0))
  levels(predictLR) = c("FAKE", "REAL")
  # confusion matrix
  cat("\n#######################\n")
  table(test$label, predictLR)
  cat("\n")
  scores[i,] <- score(predictLR, test$label)
}
# need one more iteration outside for-loop to account for remaining
# observations (6335-9*633) because n/k is not an integer
i <- k
# train/test split
train <- tSparse[-split[(((i-1)*n_k)+1):dim(tSparse)[1]],]
test <- tSparse[split[(((i-1)*n_k)+1):dim(tSparse)[1]],]
# train LR model
modelLR = glm(label ~ ., data=train, family="binomial")
# predict with LR
predictLR = predict(modelLR, newdata=test, type="response")
predictLR = factor(round(predictLR, digits=0))
levels(predictLR) = c("FAKE", "REAL")
# confusion matrix
cat("\n#######################\n")
cat("\n")
scores[i,] <- score(predictLR, test$label)

LR_ONEGRAM_ACCURACY <- 0.8413687
LR_ONEGRAM_PRECISION <- 0.8083161
LR_ONEGRAM_RECALL <- 0.8910022
LR_ONEGRAM_F1 <- 0.8419598

LR_BIGRAM_ACCURACY <- 0.7685728
LR_BIGRAM_PRECISION <- 0.7216141
LR_BIGRAM_RECALL <- 0.8731681
LR_BIGRAM_F1 <- 0.790001

LR_TRIGRAM_ACCURACY <- 0.5428675
LR_TRIGRAM_PRECISION <- 0.523995
LR_TRIGRAM_RECALL <- 0.9242782
LR_TRIGRAM_F1 <- 0.6684849
```


```{r N-Grams Logistic Regression, echo=F, message=F, warning=F}
# initialize scores matrix
scores2 <- matrix(,nrow=k,ncol=4)
scores3 <- matrix(,nrow=k,ncol=4)

# Logistic Regression
for(i in 1:(k-1)) {
  # train/test split
  train2 <- tSparse2[-split[(((i-1)*n_k)+1):(i*n_k)],]
  test2 <- tSparse2[split[(((i-1)*n_k)+1):(i*n_k)],]
  train3 <- tSparse3[-split[(((i-1)*n_k)+1):(i*n_k)],]
  test3 <- tSparse3[split[(((i-1)*n_k)+1):(i*n_k)],]
  # train LR model
  modelLR2 = glm(label ~ ., data=train2, family="binomial")
  modelLR3 = glm(label ~ ., data=train3, family="binomial")
  # predict with LR
  predictLR2 = predict(modelLR2, newdata=test2, type="response")
  predictLR2 = factor(round(predictLR2, digits=0))
  levels(predictLR2) = c("FAKE", "REAL")
  predictLR3 = predict(modelLR3, newdata=test3, type="response")
  predictLR3 = factor(round(predictLR3, digits=0))
  levels(predictLR3) = c("FAKE", "REAL")
  # confusion matrix
  cat("\n#######################\n")
  cat("2-gram\n")
  table(test2$label, predictLR2)
  cat("\n")
  scores2[i,] <- score(predictLR2, test2$label)
  cat("\n#######################\n")
  cat("3-gram\n")
  table(test3$label, predictLR3)
  cat("\n")
  scores3[i,] <- score(predictLR3, test3$label)
}
# need one more iteration outside for-loop to account for remaining
# observations (6335-9*633) because n/k is not an integer
i <- k
# train/test split
train2 <- tSparse2[-split[(((i-1)*n_k)+1):dim(tSparse2)[1]],]
test2 <- tSparse2[split[(((i-1)*n_k)+1):dim(tSparse2)[1]],]
train3 <- tSparse3[-split[(((i-1)*n_k)+1):dim(tSparse3)[1]],]
test3 <- tSparse3[split[(((i-1)*n_k)+1):dim(tSparse3)[1]],]
# train LR model
modelLR2 = glm(label ~ ., data=train2, family="binomial")
modelLR3 = glm(label ~ ., data=train3, family="binomial")
# predict with LR
predictLR2 = predict(modelLR2, newdata=test2, type="response")
predictLR2 = factor(round(predictLR2, digits=0))
levels(predictLR2) = c("FAKE", "REAL")
predictLR3 = predict(modelLR3, newdata=test3, type="response")
predictLR3 = factor(round(predictLR3, digits=0))
levels(predictLR3) = c("FAKE", "REAL")
  # confusion matrix
cat("\n#######################\n")
cat("2-gram\n")
table(test2$label, predictLR2)
cat("\n")
scores2[i,] <- score(predictLR2, test2$label)
cat("\n#######################\n")
cat("3-gram\n")
table(test3$label, predictLR3)
cat("\n")
scores3[i,] <- score(predictLR3, test3$label)

# k-fold average scores
avg_score2 <- rep(NA, 4)
avg_score3 <- rep(NA, 4)
for(i in 1:4) {
  avg_score2[i] <- mean(scores2[,i])
  avg_score3[i] <- mean(scores3[,i])
}
avg_acc2 <- 0.8274589
avg_prec2 <- 0.7635951
avg_rec2 <- 0.9477520
avg_f12 <- 0.8456242
avg_acc3 <- 0.8201932
avg_prec3 <- 0.7524047
avg_rec3 <- 0.9537779
avg_f13 <- 0.8410367
```


```{r N-Grams Random Forest, echo=F, message=F, warning=F}
library(randomForest)
# initialize scores matrix
scores <- matrix(,nrow=k,ncol=4)

# warning: this takes 6-8hrs
# I summarized the scores below
for(i in 1:(k-1)) {
  # train/test split
  train3 <- tSparse3[-split[(((i-1)*n_k)+1):(i*n_k)],]
  test3 <- tSparse3[split[(((i-1)*n_k)+1):(i*n_k)],]
  # train RF model
  modelRF3 = randomForest(label ~ ., data=train3)
  # predict with RF
  predictRF3 = predict(modelRF3, newdata=test3)
  # confusion matrix
  cat("\n#######################\n")
  table(test3$label, predictRF3)
  cat("\n")
  scores[i,] <- score(predictRF3, test3$label)
}
# need one more iteration outside for-loop to account for remaining
# observations (6335-9*633) because n/k is not an integer
i <- k
# train/test split
train3 <- tSparse3[-split[(((i-1)*n_k)+1):dim(tSparse3)[1]],]
test3 <- tSparse3[split[(((i-1)*n_k)+1):dim(tSparse3)[1]],]
# train RF model
modelRF3 = randomForest(label ~ ., data=train3)
# predict with RF
predictRF3 = predict(modelRF3, newdata=test3)
# confusion matrix
cat("\n#######################\n")
table(test3$label, predictRF3)
cat("\n")
scores[i,] <- score(predictRF3, test3$label)
# k-fold  scores
kfoldF1 <- c(0.8978224, 0.9096672, 0.9281250, 0.9129771, 0.9304348, 0.9318182, 0.9093904, 0.9193303, 0.9298532, 0.9167975)
```



